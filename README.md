# Projet-scrapping-CAC40
Objectif du projet:
Lâ€™objectif de ce projet est de construire un pipeline complet de scraping automatisÃ© dâ€™un site web dynamique, et dâ€™afficher en temps rÃ©el les donnÃ©es rÃ©coltÃ©es sur un dashboard interactif dÃ©veloppÃ© avec Dash en Python. Le projet inclut :

Une extraction rÃ©guliÃ¨re des donnÃ©es via un script Bash.

Le stockage en sÃ©rie temporelle de ces donnÃ©es dans un fichier .csv.

Un dashboard contenant :

La valeur actuelle de la donnÃ©e.

Un graphique dynamique retraÃ§ant lâ€™Ã©volution au cours du temps.

Un rapport journalier gÃ©nÃ©rÃ© chaque soir Ã  20h (statistiques, rÃ©sumÃ©â€¦).

Une mise Ã  jour automatique via cron toutes les 5 minutes.

ğŸŒ Site web choisi:
Nous avons choisi de suivre lâ€™Ã©volution de la paritÃ© euro/dollar (EUR/USD) sur le site :

ğŸ”— https://forex.tradingsat.com/cours-euro-dollar-FX0000EURUSD/

Ce site a lâ€™avantage de proposer une structure HTML stable et permet dâ€™accÃ©der Ã  la donnÃ©e de maniÃ¨re fiable.

ğŸ”§ Pourquoi ce site ?
Nous avons initialement tentÃ© de rÃ©cupÃ©rer les donnÃ©es Ã  partir de sites comme Barchart, Investing.com, ou TradingView, mais nous avons rencontrÃ© de nombreuses limitations techniques :

Blocage de requÃªtes non-authentifiÃ©es (403 Forbidden).

Chargement des donnÃ©es via JavaScript dynamique, rendant le scraping Bash impossible.

Protection contre les bots et taux de rafraÃ®chissement trÃ¨s Ã©levÃ©.

Le site tradingsat.com sâ€™est rÃ©vÃ©lÃ© Ãªtre un bon compromis, avec une donnÃ©e accessible directement dans le HTML.

âš™ï¸ MÃ©thodologie
1. ğŸ“¥ Scraping avec Bash
Nous avons utilisÃ© curl et grep dans un script bash (scrape.sh) pour extraire la paritÃ© EUR/USD. Exemple simplifiÃ© de la commande utilisÃ©e :

bash
Copier
Modifier
curl -s "https://forex.tradingsat.com/cours-euro-dollar-FX0000EURUSD/" | grep ...
La donnÃ©e est ensuite formatÃ©e et ajoutÃ©e avec timestamp dans un fichier prix_eur_usd.csv.

2. ğŸ“ˆ Visualisation avec Dash (Python)
Nous avons construit une interface avec le framework Dash qui permet :

Lâ€™affichage de la derniÃ¨re paritÃ© EUR/USD scrappÃ©e.

Un graphique dynamique (utilisant Plotly) affichant lâ€™Ã©volution depuis le lancement du projet.

Un rapport journalier (mis Ã  jour chaque jour Ã  20h via cron) affichant :

Ã‰cart-type ( VolatilitÃ© de la paritÃ© EUR/DOL)

Valeur min/max du jour

3. ğŸ•’ Automatisation avec Cron
Deux tÃ¢ches cron sont planifiÃ©es :

â±ï¸ Toutes les 5 minutes : exÃ©cution du script de scraping et mise Ã  jour du data.csv.

ğŸ“… Chaque jour Ã  20h : gÃ©nÃ©ration du rapport statistique.

ğŸ“ Arborescence du projet
///venv
///.gitignore
///README.md
///grep.sh
///main.py
///prix_eur_usd.csv
///scrapper.py
///scrapper.sh

ğŸ’¼ RÃ©partition du travail:
CYPRIEN DUCEUX: Choix et test du site internet 

Extraction des donnÃ©s dash

CrÃ©ation du fichier CSV

ALgorithme Python pour le Dash Bord

CHARLIE DELPLACE: Automatisation avec cron 

ImplÃ©mentation de la machine virtuelle

ALgorithme Python pour le Dash Bord


âœ¨ Conclusion
Ce projet nous a permis de maÃ®triser un workflow complet alliant Bash, Python, gestion de cron, visualisation avec Dash, et traitement de donnÃ©es. 
MalgrÃ¨s les difficultÃ©s rencontrÃ©es notamment dans l'extraction des donnÃ©es, nous avons trouvÃ© le projet passionant et trÃ¨s formateur.
